The Book and the Chatbot
January 12, 2026 · Response to: Cognitive Revolution, "AI's Energy & Water Demands"
In my previous post, I wrote about how the claim that AI consumes catastrophic amounts of water became "obvious" through repetition without scrutiny. But there's a follow-up question worth asking: if the actual numbers are so much smaller than people assume, what happens when you compare AI's environmental costs to other things we take for granted?
Andy Masley, on the Cognitive Revolution podcast, tells a story that makes this comparison concrete:
I recently interacted with a large educational institution where the people in charge of the technology there were just completely convinced that this isn't actually so bad and we should really be able to pay for this for our low-income students especially to have access to chatbots and stuff. But we're getting a lot of pushback from a lot of different places basically being like this will be bad for the environment if we do this to the point that we can't do this—and like using that logic it also wouldn't make sense to ever purchase books for any students.
— Andy Masley, Cognitive Revolution
That last line might sound like hyperbole. It isn't. Let's look at the numbers.
What It Takes to Make a Book
Paper production is one of the most energy and water-intensive manufacturing processes. According to industry analyses, producing one kilogram of paper generates about one kilogram of CO2—1.2 kg for virgin fiber, 0.7 kg for recycled. The pulp and paper industry is the fifth largest consumer of energy globally and the third largest industrial polluter in North America.
For water, the numbers are even more striking. It takes approximately 10 liters of water to produce a single sheet of paper. A 300-page book (150 sheets) would require roughly 1,500 liters of water just for the paper—before accounting for printing, binding, or transportation.
When researchers have calculated the total carbon footprint of a printed book, estimates range from 2.71 kg CO2 per book (a Journal of Industrial Ecology study) to 7.5 kg CO2 per book (other assessments). Let's use the conservative estimate: 2.7 kg, or 2,700 grams of CO2.
What It Takes to Run a Chatbot
Masley's analysis puts the median ChatGPT prompt at roughly 0.3 grams of CO2, once you account for inference, cooling, training costs, and embodied hardware. For water, the actual consumption is about 2 milliliters per prompt—not the "bottle of water" that circulates in popular discourse.
Now we can do the math.
Carbon: If one book produces 2,700 grams of CO2 and one prompt produces 0.3 grams, then one book equals approximately 9,000 ChatGPT prompts. Using the higher estimate of 7.5 kg per book, you get around 25,000 prompts.
Water: If one book requires 1,500 liters of water and one prompt requires 2 milliliters, then one book equals approximately 750,000 ChatGPT prompts.
To put this in perspective: a student could send 9,000 prompts to ChatGPT—enough to use it dozens of times a day for an entire semester—and produce the same carbon emissions as manufacturing a single textbook. For water, they could prompt ChatGPT three-quarters of a million times before matching what it took to make that book.
Bits Versus Atoms
Why is the gap so large? Masley articulates the principle clearly: bits are dramatically less massive than atoms, and therefore dramatically easier to manipulate.
Manufacturing a physical object means moving matter around. Trees must be harvested, transported, pulped. Water must be heated. Chemicals must be applied. Paper must be dried—and drying accounts for 70% of the energy use in paper production. Then the paper must be printed, bound, shipped to warehouses, shipped again to stores or schools.
Running a chatbot means electrons flowing through silicon. The chips are extraordinarily optimized—as Masley notes, "so many people are being paid to think in really complicated ways of optimizing the energy use of these chips as much as possible." A single prompt uses about as much energy as running a microwave for one second.
This isn't unique to AI. Computing in general is wildly efficient compared to physical manufacturing. Masley offers a memorable illustration: running a game of Minecraft in 1950 would have required approximately half the energy output of the United States. Now it runs on a laptop. That's how much optimization has happened in moving bits around.
The Absurdity of Selective Concern
Here's what makes the educational institution story so striking. The objection to subsidizing chatbot access for low-income students was framed as environmental concern. But that same institution presumably purchases textbooks, prints syllabi, heats classrooms, and runs computer labs—all of which have larger environmental footprints per unit of educational value than chatbot access.
If the environmental cost of 9,000 prompts is genuinely unacceptable, then the environmental cost of one textbook must also be unacceptable. If 750,000 prompts' worth of water is too much, then so is one book's worth of water. The logic doesn't stop where it's convenient.
This is the pattern Masley identifies throughout his analysis: people focus on AI's resource use not because it's large in absolute terms, but because it's new and they're already skeptical of it for other reasons. Meanwhile, the "useful" emissions—driving to campus, heating buildings, manufacturing physical course materials—escape scrutiny because they're familiar.
What This Means for Argumentation
I'm not arguing that environmental concerns are illegitimate or that we shouldn't think carefully about the resource costs of new technologies. I'm arguing that selective application of environmental logic reveals something other than environmental concern.
If you object to AI on environmental grounds but don't apply the same standard to books, cars, hamburgers, hot showers, or any of the other activities that dwarf AI's footprint, you're not actually making an environmental argument. You're making a different argument and dressing it in environmental clothing.
That's not persuasive. Worse, it undermines legitimate environmental arguments by associating them with innumeracy and motivated reasoning. As Masley puts it: "I'm pretty worried that a lot of my fellow AI critics are potentially diluting a lot of the points that they make by just adding on... 'and every time it does that it uses like a drop of water, isn't that terrible?' The second point just takes away from the first."
If you want to argue against AI access for students, argue against it on grounds that survive contact with actual comparisons. The environmental argument doesn't.
Note: The calculations in this post are approximate and drawn from multiple sources with varying methodologies. The point is not precision but order of magnitude—and the orders of magnitude are not close.