Automation, Accountability, and the Myth of Lost Humanity
&larr; Back to Home
Automation, Accountability, and the Myth of Lost Humanity
Responding to Jona’s “The Vibe Schism: Factory Farming Code vs. The Art of Verification”
February 2026
In “The Vibe Schism: Factory Farming Code vs. The Art of Verification,” Jona critiques the rise of AI-assisted “vibe coding,” warning that rapid automation risks creating “insecure spaghetti” code and engineers who have lost architectural mastery. He frames AI tools as reckless junior developers: fast, productive, but prone to error without human oversight. He writes:
“The Industrialist Solution: Because the AI is a reckless junior, we must become better managers. We need to build orchestration frameworks (like Yegge’s ‘Vibe Coder’ tool) to corral them.
…The mastermind remains in the machine, but only if the human refuses to just ‘vibe’ and starts to truly engineer.”
-- Jona, The Vibe Schism: Factory Farming Code vs. The Art of Verification, February 8, 2026
I agree with Jona that verification is becoming the central task in software development and that AI introduces real risks if left unchecked. His warning about the verification gap—the distance between rapid AI-assisted creation and careful review—is both accurate and timely. Security vulnerabilities, technical debt, and code fragility are genuine challenges.
Where I diverge is in the implied prescription: that resisting AI or limiting its use is the way to preserve mastery. I argue the opposite: AI does not remove human agency; it shifts it. Automation allows humans to focus on higher-order judgment, creativity, and accountability rather than repetitive execution. Mastery is no longer defined by typing every line correctly; it is defined by making deliberate decisions under constraints.
Automation, Verification, and Security
The verification gap highlighted by Jona parallels the concept of security in software development. AI-generated code is capable of producing more lines at faster speed, but vulnerabilities do not execute themselves. Humans still approve, deploy, and manage systems. As IBM explains:
“AI-powered autocompletion and code synthesis … allows developers to focus on more complex and creative tasks rather than boilerplate code … AI-driven tools help allocate resources, schedule tasks more efficiently and monitor system performance in real time, optimizing deployment and preventing potential failures.”
-- IBM, AI in Software Development, ibm.com
This demonstrates that AI enhances human oversight rather than replacing it. Automation shifts responsibility upward: from typing syntax correctly to deciding what should exist, what risks are acceptable, and how to mitigate them. Security, in this sense, becomes a moral and procedural obligation, not a technical impossibility.
Rugby: Risk, Automation, and Deliberate Action
Sports, particularly rugby, illustrate this principle vividly. When I ask AI tools for strategies to optimize recovery, prevent injury, or improve efficiency, teammates often laugh, assuming that these tools diminish grit or courage. In reality, the opposite is true.
No AI algorithm takes a tackle for me. No recovery protocol eliminates risk. What these tools do is clarify the consequences of my actions. Understanding my limits forces me to decide deliberately which risks I will take and when. Injury management becomes accountable, intentional, and strategic.
The same dynamic applies to Jona’s AI agents. Just as a player faces deliberate consequences within clear rules, developers face accountable consequences for their choices. Automation does not remove risk; it makes it meaningful.
The Magic of Constraints and Creativity
Jona’s post worries that automation “hollows out” mastery and creativity, leaving only sterile efficiency. I argue that constraints, including automated systems and clear rules, enhance creativity. Karl Newell, in his foundational work on motor learning, observes:
“Movement coordination patterns emerge as a function of constraints imposed by the task, the environment, and the organism.”
-- Karl M. Newell, Constraints on the Development of Coordination, 1986
Constraints focus human ingenuity. In rugby, strict rules, performance protocols, and video review force players to innovate within clear boundaries. In software, automated code generation removes arbitrary minutiae, freeing humans to focus on architecture, design, and strategic risk. The friction has not disappeared—it has migrated to moments that matter.
Security as Accountability, Not Safety
A crucial extension of both coding and sports is security. In both domains, automation does not eliminate risk—it makes responsibility unavoidable. In rugby, concussion protocols and injury tracking prevent plausible deniability. In software, AI code generators do not bear liability; humans do.
Security is fundamentally about traceability: knowing who is responsible when failures occur. In software, a system may be automatically deployed, but vulnerabilities are ultimately a human choice to approve, ship, or ignore. In rugby, AI-informed recovery plans do not make collisions safe—they make returning to play a deliberate ethical decision. In both cases, automation concentrates risk in the hands of those accountable, rather than diffusing or hiding it.
Drama, Mastery, and the Migration of Risk
Jona worries that automation drains drama from engineering. I argue that drama migrates rather than disappears. Before automation, tension often emerged from procedural inconsistency—uncertain build processes, unpredictable merges, or inconsistent officiating in sports. After automation, tension shifts to human execution under precise constraints.
In rugby, consistent enforcement of rules and monitoring of recovery does not reduce challenge; it intensifies it. Players must adapt in real time, make high-stakes decisions, and face direct consequences. In software, AI reduces routine error but amplifies the importance of judgment, design, and ethical decision-making.
Conclusion: Mastery in the Age of Automation
Jona correctly identifies the verification gap and the risks of unverified AI outputs. He is right to insist that engineers must not “just vibe.” But the solution is not limiting automation—it is elevating human responsibility.
Whether in coding, sports, or security, the pattern is clear: automation shifts risk upward—from execution to judgment. Mastery now means making deliberate choices under clear constraints, verifying outcomes, and owning consequences. AI does not remove humanity or creativity. It forces humans to confront their agency fully.
In rugby, this translates to players making intentional decisions about tackles, stamina, and recovery. In software, it means architects verifying every deployment and managing systemic risk. Across domains, automation exposes responsibility, concentrates risk where it matters, and makes human judgment indispensable.
The fear is not that AI will replace humans—it is that humans will fail to rise to the responsibility that automation makes unavoidable.
Word count: ~1,210
External source: IBM, AI in Software Development, ibm.com
Network engagement: Jona, The Vibe Schism: Factory Farming Code vs. The Art of Verification, February 8, 2026