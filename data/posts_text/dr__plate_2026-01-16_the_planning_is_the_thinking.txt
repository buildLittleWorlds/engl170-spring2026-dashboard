The Planning Is the Thinking
January 16, 2026 · Response to: Matt Pocock on Plan Mode
Matt Pocock was an AI skeptic. He thought AI couldn't write decent code, couldn't understand his codebase, couldn't match the instincts he'd built over years. Then he tried "plan mode" and never went back. The strange thing: the feature that converted him doesn't let the AI do anything. Plan mode disables the AI's ability to write files. It can only read, explore, and produce a plan. The AI is forced to think before it acts. That constraint changed everything.
This matters beyond coding because it reveals something about the relationship between AI tools and thinking—something that contradicts the dominant critique.
The Argument Against
Ted Chiang has become the most articulate voice of AI skepticism in creative and educational contexts. His position is clear: writing is cognitive training, and the value lies in the mental exertion, not the output. In a Q&A at Princeton, he offered direct guidance to students:
Using ChatGPT undermines education's purpose by enabling students to avoid the mental exertion necessary for intellectual growth.
— Ted Chiang, "The Incompatibilities Between Generative AI and Art"
The logic follows: if you use AI to write, you skip the thinking that makes writing valuable. The product might look acceptable, but the process that develops your mind has been bypassed. Chiang draws an implicit comparison: using AI to write is like using a calculator before you understand arithmetic. You get answers but lose the capacity to reason.
This is a serious argument. It deserves a serious response, not dismissal. Chiang isn't worried about job displacement or stylistic degradation. He's worried about what happens inside the writer's head. If writing is exercise for the mind, AI is a wheelchair you didn't need.
What Plan Mode Reveals
Here's what Chiang's argument assumes: that AI assistance means skipping the hard cognitive work. Plan mode demonstrates this isn't necessarily true. The workflow Pocock describes forces thinking before execution:
You describe what you want—which requires articulating your intent
The AI asks clarifying questions—which you must answer thoughtfully
You review the plan and decide if it's right—which demands evaluation and judgment
Only then does execution happen
Pocock calls this "rubber ducking"—the practice of talking through a problem to clarify it. "No one ever knows what they want," he quotes from The Pragmatic Programmer. The planning dialogue forces you to figure out what you want. By the time the AI starts writing, the thinking has already happened.
Hashing out the requirements before you get to code is something we've been doing for 50 years as developers. And there's no reason why we should stop now.
— Matt Pocock
The thinking didn't disappear. It moved to a different phase. Chiang assumes that when AI handles the output, no thinking occurs. But plan mode puts the thinking where it arguably always belonged: in the planning, not the typing.
Translation to Writing
Does this apply to writing? The skeptic might say coding and writing are fundamentally different—code has clear success criteria (it runs or crashes), while writing involves judgment all the way through.
True, but not as different as it sounds. Both activities involve turning intent into artifact. The planning phase is where intent gets clarified. Execution is translation.
Consider how this would work for an argumentative essay:
You articulate your thesis—the AI can't do this for you
You identify the counterarguments worth addressing—judgment call
You decide what evidence matters—another judgment call
You approve or revise the structural plan—critical evaluation
The AI drafts prose following your plan—execution
You revise—more judgment
Where did the thinking go? It's in every step except the drafting. And even the drafting produces something you then evaluate. The "mental exertion" Chiang values isn't absent—it's concentrated where it matters most.
Pocock's "colleague who forgets everything" metaphor is useful here. Imagine a research assistant who's brilliant but has no memory of your project. You wouldn't let them just start working. You'd plan first, make sure they understand the goal, review their approach before they commit. That's not outsourcing thinking—that's managing a tool.
Why This Matters
If Chiang is right—if any AI assistance in writing means cognitive decline—then the only honest position is full refusal. No AI for drafting, no AI for research, no AI for editing. The tool is inherently corrupting.
But if plan mode is evidence that workflow design determines whether thinking happens, then the question changes. It's not "AI or no AI." It's "what workflow preserves the thinking while gaining efficiency in execution?"
This matters for writers, researchers, students—anyone whose work involves turning ideas into text. The choice isn't between intellectual integrity and AI assistance. The choice is between workflows that preserve thinking and workflows that skip it. Plan mode suggests the former is possible.
Where Chiang Is Right
Chiang is right that thinking matters. He's right that a tool making output easier can make thinking less likely. He's right to worry about what happens inside the writer's head.
He's wrong that AI assistance necessarily removes thinking. Plan mode is evidence that the relationship between tool and cognition is a design choice, not a fixed property of the technology. The AI skeptic who converted didn't convert because the AI got smarter. He converted because a workflow forced him to think first.
The planning is the thinking. The execution is just typing.