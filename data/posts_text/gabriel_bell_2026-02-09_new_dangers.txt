New Dangers
February 9, 2026
In his post "New Vulnerabilities," Dr. Plate offers a deeply human perspective on the anxieties surrounding artificial intelligence. He compares the introduction of AI into our lives and institutions to the start of a new romantic relationship or the birth of a child. His central argument is that growth inherently requires vulnerability—that we cannot "patch" risks that haven't manifested yet, and that the only way to truly understand a new thing is to inhabit it. It is a poetic and persuasive defense of engagement over caution.
However, when we transition from the intimate sphere of personal relationships to the global sphere of ubiquitous technology, the logic of "vulnerability as growth" begins to fray. While I admire the emotional resonance of Plate’s analogy, I believe it overlooks a fundamental distinction: the difference between private risk and systemic consequence. A relationship affects a few people; a ubiquitous technology disrupts the status quo for millions. Because of this disparity in scale, we cannot apply the same standard of "forgivable recklessness" to AI that we do to the human heart.
The Manageable Scale of Personal Risk
Plate’s analogy rests on the idea that the "security vulnerabilities" of a relationship—anxieties, obligations, and the potential for heartbreak—are the "cost of the new thing." He argues that waiting until one is "fully healed" or "financially stable" before taking a leap is a form of paralysis that prevents growth. In the context of a relationship, he is absolutely right.
When two people decide to enter a relationship, they are entering a private contract of vulnerability. If the relationship fails, the damage, while potentially devastating, is localized. It is a tragedy for the individuals involved, perhaps a difficult transition for their immediate families, but the "attack surface" is limited. Because the scale is small, we allow for—and even celebrate—a certain degree of spontaneity. We "forgive" the person who falls in love "too fast" because the stakes, in the grand scheme of society, are manageable. The risk is proportional to the reward, and the fallout is contained within a private ecosystem.
In this sphere, Plate’s mantra of "move forward, fix what breaks" makes sense. You learn to be a partner by being one. You learn to be a parent by failing in real-time with a real child. The "failures" here are the curriculum of the human experience.
The Ubiquity of Technological Disruption
The problem arises when we attempt to map this same logic onto a technology as "status-quo-disrupting" as AI. Unlike a new partner or a newborn child, AI is not entering a private home; it is being integrated into the foundational architecture of our economy, our information systems, and our cognitive habits. When Plate argues that "the vulnerability is the live evidence that your world has gotten larger," he is speaking to the expansion of individual potential. But when a technology becomes ubiquitous, it doesn't just expand the world; it replaces the old one. We aren't just adding a "new person" to the global conversation; we are changing the medium and the rules of the conversation itself.
The vulnerabilities introduced by AI are not just "uncomfortable" or "destabilizing" in the way a new relationship is. They are systemic. If 45% of AI-generated code contains security vulnerabilities, as Plate notes from Jonas’s findings, we aren't just talking about a "learning moment" for a single developer. We are talking about the potential compromise of financial systems, power grids, and private data on a global scale. If AI-driven "vibe coding" leads to a "verification gap," we aren't just failing to "patch" a personal flaw; we are eroding the collective capacity for critical thought and technical mastery across an entire generation of workers.
The Problem of Reversibility and Consent
There is also the question of reversibility. If a relationship is toxic or a mistake, there is a path to exit, however painful. The "vulnerabilities" can be addressed by retreating to a previous state of independence. But technology is rarely reversible. Once AI is integrated into the workflow of every major corporation and the curriculum of every university, there is no "breaking up" with it. We cannot "retreat to where things were stable" because the old infrastructure—the "stable system" Plate mentions—is often dismantled to make room for the new.
Furthermore, relationships are built on mutual consent. Two people choose to take the risk together. But the "ubiquitous" nature of AI means that the risk is often forced upon those who did not sign up for the "relationship." The student who wants to learn to write without AI, the artist whose work is used for training data, or the worker whose job is automated away did not choose to "inhabit" this vulnerability. They are being pulled into the "growth" Plate describes without the agency that usually accompanies a leap of faith.
Why Thoroughness is Mandatory
Plate suggests that "the understanding [institutions] are waiting for is produced by the engagement they're forbidding." He views caution as a "fear that prevents learning." However, in the realm of large-scale technology, caution isn't just fear—it’s the Precautionary Principle. When we introduce a new drug to the market, we do not say, "We’ll learn about the side effects by giving it to everyone and fixing what breaks." We demand rigorous, thorough examination before ubiquity. We do this because the scale of potential harm outweighs the benefit of "fast growth."
AI, in its current state, is being treated more like a social media app—"move fast and break things"—than a foundational societal shift. I would argue that the "status-quo-disrupting" nature of AI demands a level of scrutiny that would be stifling in a romance but is essential in governance. We can be forgiven for not wanting to take "as much time" before entering a relationship because we are only risking our own hearts. But when we risk the integrity of public discourse, the security of our digital lives, and the value of human expertise, "thoroughness" is not a sign of fear—it is a sign of responsibility.
Conclusion: Personal Bravery vs. Collective Diligence
Dr. Plate is right that we cannot patch a vulnerability that doesn't exist yet. He is right that engagement produces a type of knowledge that observation never can. But he is applying a philosophy of personal bravery to a problem of collective safety. We should be brave in our personal lives. We should embrace the "messy failing" of parenthood and the "unraveling" of a new dinner conversation. These are the things that make life worth living. But AI is not a life partner. It is a tool of immense power and unpredictable reach.
The person who refuses a relationship until it is "safe" may indeed never start one. But the society that refuses to deploy a ubiquitous technology until it is "safe" is a society that values its citizens over its speed. We must be willing to examine AI with a thoroughness that would ruin a romance but might just save a civilization. We can afford to be impulsive with our hearts; we cannot afford to be impulsive with our future.