<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Ben Teismann | ENGL 170 Snapshot</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=Instrument+Sans:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <div class="grain-overlay"></div>

  <header class="site-header snapshot-header">
    <div class="header-content">
      <div class="masthead">
        <span class="issue-label">Writer Snapshot</span>
        <h1 class="site-title">Ben Teismann</h1>
        <p class="site-subtitle">ENGL 170 Â· Composition II</p>
      </div>
      <div class="header-nav-group">
        <a href="https://blt279.github.io" target="_blank" rel="noopener" class="header-nav-link">Visit Blog &rarr;</a>
        <a href="../directory.html" class="header-nav-link">&larr; Directory</a>
      </div>
    </div>
  </header>

  <main class="main-content snapshot-content">
    <!-- Summary Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Overview</h2>
      <div class="snapshot-summary">
        <p>Ben began January making the case that AI threatens the emotional "soul" of automotive design and creates dangerous autonomy gaps in Tesla's marketing. By February, he had launched a sweeping six-part indictment that reframes the entire project: the problem with AI in cars is not just aesthetics&mdash;it is moral, structural, economic, racial, and civil libertarian. His nine posts form a comprehensive "Case Against the AI Car": AI's "Moral Black Box" evades accountability when vehicles kill; its technical fragility means the "last 1%" of edge cases remains catastrophically unsolved; its network connectivity transforms vehicles into remotely hackable weapons; its automation destroys 3.5 million trucking jobs and hollows out rural economies; its computer vision carries lethal racial bias against darker-skinned pedestrians; and its surveillance architecture converts the cabin into a biometric data farm. Where others debate whether AI makes cars better, Ben argues the AI car is a moral, safety, and social failure.</p>
      </div>
    </section>

    <!-- Key Themes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Key Themes</h2>
      <ul class="theme-list">
        <li class="theme-item">AI and car design / homogenization</li>
        <li class="theme-item">Autonowashing and the autonomy gap</li>
        <li class="theme-item">Human craftsmanship pipeline</li>
        <li class="theme-item">The Moral Black Box / accountability gap</li>
        <li class="theme-item">Technical fragility and the "last 1%" problem</li>
        <li class="theme-item">Cybersecurity and remotely weaponizable vehicles</li>
        <li class="theme-item">Blue-collar displacement and rural economy destruction</li>
        <li class="theme-item">Algorithmic bias in computer vision (racial disparity)</li>
        <li class="theme-item">Automotive surveillance and biometric privacy</li>
      </ul>
    </section>

    <!-- Core Arguments Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Core Arguments</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Moral Black Box</span>
          </div>
          <p class="snapshot-post-description">When AI kills, no one is responsible. The "Accountability Gap" diffuses blame across manufacturers, software providers, and sensor makers, all pointing to the "human in the loop" who had 0.2 seconds to intervene. Private corporations are writing public moral policy in opaque code, encoding "Trolley Problem" decisions without democratic accountability. "A society that allows machines to decide its casualties is a society that has lost its way."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Technical Fragility and the Sunk Cost of Autonomy</span>
          </div>
          <p class="snapshot-post-description">The AI car industry is trapped in a "Sunk Cost Fallacy." AI handles the easy 99% but fails catastrophically on edge cases&mdash;a rogue shopping cart, a traffic cop's hand signals, a blizzard. These aren't teething problems; they are structural limitations. The resulting complexity makes cars more expensive and less repairable: a fender bender now costs $10,000 because every smart bumper must be precisely calibrated. "The AI experiment in our cars has failed."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Remotely Hackable Weapons</span>
          </div>
          <p class="snapshot-post-description">Any connected system is a hackable system. Modern AI vehicles contain 100+ million lines of code with "adversarial attack" vulnerabilities&mdash;specific stickers can trick AI into misreading a stop sign as a speed limit sign. Over-the-Air update systems mean a single zero-day exploit could theoretically push malicious code to millions of vehicles simultaneously. "The open road is just one hack away from a catastrophe." Ben calls for "air-gapped" safety systems where critical driving functions are physically separated from internet connectivity.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Blue-Collar Erasure</span>
          </div>
          <p class="snapshot-post-description">3.5 million professional truck drivers face elimination. Trucking is one of the few remaining career paths offering family-sustaining wages without a four-year degree&mdash;AI automation targets it precisely because it eliminates rest breaks, health insurance, and pension contributions. Beyond jobs: the "ecosystem of the road" that supports Nebraska diners, Ohio motels, and rural repair shops collapses when an AI truck doesn't stop for coffee. The "transition" model of human monitoring creates "automation complacency," stripping skilled professionals down to biological backup systems.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Algorithmic Apartheid on the Road</span>
          </div>
          <p class="snapshot-post-description">Research from the Georgia Institute of Technology found AI computer vision is significantly less accurate at detecting people with darker skin tones. The training data is predominantly affluent, Western, suburban&mdash;the "baseline" human the AI protects is overwhelmingly fair-skinned. The bias extends geographically: AI is tested in well-maintained Phoenix or Palo Alto streets and performs poorly in lower-income areas with faded signage. "We are subsidizing the safety of the rich by using the rest of the population as crash-test dummies."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Surveillance Cabin</span>
          </div>
          <p class="snapshot-post-description">Driver Monitoring Systems perform real-time biometric analysis&mdash;tracking pupil dilation, heart rate variability, and micro-expressions. This data goes to insurance aggregators who generate AI "risk scores" without drivers' knowledge. NLP voice assistants store transcripts of private conversations in the cloud. The AI doesn't just navigate roads; it maps habits to create a digital twin sold to the highest bidder. "We are trading the soul of the driving experience for a digital nanny that reports back to its corporate parents."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Erosion of Automotive Soul (Original Thesis)</span>
          </div>
          <p class="snapshot-post-description">AI-driven design leads to homogenization&mdash;human designers drew from biological analogy (sailfish &rarr; McLaren P1) and cultural context that AI cannot replicate. AI optimizes for drag coefficients but cannot understand "presence." As companies replace junior roles with AI, the talent pipeline constricts: without formative years learning form through clay modeling, the industry suffers a permanent craftsmanship loss.</p>
        </div>
      </div>
    </section>

    <!-- Notable Quotes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Notable Quotes</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description">"We are creating a world of 'victimless crimes' where people die, but no one is truly responsible."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"By surrendering the creative process to algorithms, we are opting for a future of high-performance 'slop'&mdash;products that are technically perfect but emotionally bankrupt."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"We are subsidizing the safety of the rich by using the rest of the population as crash-test dummies in an unrefined experiment."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"If AI cannot protect every person on the road with 100% parity, it has no business being on the road at all."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"We are trading the soul of the driving experience for a digital nanny that reports back to its corporate parents."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"Tesla's current system turns a life-saving dream into a liability. True progress should empower the driver or protect the passenger; Tesla's often does neither."</p>
        </div>
      </div>
    </section>

    <!-- Posts Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Posts</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/TheSurveillanceCabin.html" target="_blank" rel="noopener" class="snapshot-post-title">The Surveillance Cabin</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">The AI car has converted the vehicle cabin into a biometric data farm. Driver Monitoring Systems track pupil dilation, heart rate, and micro-expressions; this data goes to insurance aggregators who raise premiums invisibly. NLP voice assistants store private conversations. The car is "a data-processing plant" that maps your habits and creates a digital twin. Calls for legislative firewalls against automotive surveillance and physical air-gaps between monitoring systems and critical driving functions.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/TheAlgorithmicBias.html" target="_blank" rel="noopener" class="snapshot-post-title">The Algorithmic Bias</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">Cites Georgia Tech research showing AI pedestrian detection is significantly less accurate for people with darker skin tones due to training data from affluent, predominantly white suburban environments. Geographic bias compounds this: systems tested in Phoenix or Palo Alto degrade sharply in lower-income urban areas with faded signage and "non-standard" pedestrian behavior. This is not a patchable bug but a structural architectural failure. "High-tech redlining, where safety is a privilege reserved for those who fit the algorithm's 'optimal' profile."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/TheDeathoftheBlue-CollarBackbone.html" target="_blank" rel="noopener" class="snapshot-post-title">The Death of the Blue-Collar Backbone</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">Autonomous trucking threatens 3.5 million drivers and the entire rural "ecosystem of the road." Companies target trucking specifically to eliminate rest breaks and benefits&mdash;savings flow to tech shareholders, not workers or consumers. The "augmentation" model (humans monitoring AI) creates automation complacency, reducing skilled professionals to "redundant biological backup systems." "Inevitability is a word often used to silence those whose lives are being destroyed."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/CybersecurityandRemoteTerror.html" target="_blank" rel="noopener" class="snapshot-post-title">Cybersecurity and Remote Terror</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">Modern AI vehicles contain 100+ million lines of code with "adversarial attack" vulnerabilities&mdash;stickers designed to fool computer vision have already been demonstrated in lab settings. OTA update systems create systemic risk: a compromised update server could theoretically push malicious code to millions of vehicles simultaneously. V2X ("smart city") communication opens additional injection attack vectors. Proposes "air-gapped" safety architecture separating critical systems from internet-connected features.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/TechnicalFragility.html" target="_blank" rel="noopener" class="snapshot-post-title">Technical Fragility: The Sunk Cost of the AI Car</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">The autonomous vehicle industry is trapped in a "Sunk Cost Fallacy"&mdash;billions spent chasing "Full Self-Driving" that is always "two years away." AI handles the predictable 99% but fails catastrophically on daily edge cases: a rogue shopping cart, a hand-signaling traffic cop, a blizzard obscuring lane markings. A software "glitch" is erratic and unreplicable in ways mechanical failures are not. The result: cars that cost more and are less repairable than their mechanical predecessors.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/TheMoralBlackBox.html" target="_blank" rel="noopener" class="snapshot-post-title">The Moral Black Box: Death by Algorithm</a>
            <span class="snapshot-post-date">February 13, 2026</span>
          </div>
          <p class="snapshot-post-description">When AI-controlled vehicles kill, the "Accountability Gap" means no one is truly responsible&mdash;manufacturers, software providers, and sensor makers all point at each other or blame the "human in the loop." Private software engineers in Silicon Valley are encoding Trolley Problem moral frameworks without democratic oversight. AI has no concept of a human life's value: it processes humans as "bounding boxes" with probability weights. "A society that allows machines to decide its casualties is a society that has lost its way."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/the-dying-automotive-soul.html" target="_blank" rel="noopener" class="snapshot-post-title">AI Designing Cars (The Erosion of the Automotive Soul)</a>
            <span class="snapshot-post-date">January 18, 2026</span>
          </div>
          <p class="snapshot-post-description">AI-driven design threatens emotional and cultural dimensions of automobiles. Human designers drew from biological analogy (sailfish &rarr; McLaren P1) and cultural context&mdash;leaps AI cannot make. AI optimizes for drag and manufacturing ease but cannot comprehend "presence." Result: design homogenization across brands, a "craftsmanship crisis" as junior designers are replaced by prompt engineers, and vehicles disconnected from the people who drive them.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/the-illusion-of-autonomy.html" target="_blank" rel="noopener" class="snapshot-post-title">The Illusion of Autonomy: Why Tesla's "Full Self-Driving" is a Dangerous Detour</a>
            <span class="snapshot-post-date">January 16, 2026</span>
          </div>
          <p class="snapshot-post-description">Critiques Tesla on safety, technical, and ethical grounds. The "Autonomy Gap" between marketing and capability encourages dangerous over-reliance (Level 5 behavior from a Level 2 system). Tesla's vision-only approach fails on edge cases&mdash;phantom braking, white trucks against bright sky. Rolling out "Beta" software uses the public as crash-test dummies. Tesla shields itself from liability while consumers bear the physical and legal risks of system failure.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://blt279.github.io/welcome-to-my-blog.html" target="_blank" rel="noopener" class="snapshot-post-title">Welcome To My Blog</a>
            <span class="snapshot-post-date">January 15, 2026</span>
          </div>
          <p class="snapshot-post-description">Introduction post establishing the blog's automotive and technology focus.</p>
        </div>
      </div>
    </section>

    <!-- Connections Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Network Connections</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description"><strong>Thematic overlap:</strong> Gabriel Bell (human relevancy, value of craft), Dominic Debro (surveillance capitalism critique&mdash;Ben's "Surveillance Cabin" extends Dominic's Panopticon concerns into automotive space), Jacob Brunts (Ben's algorithmic bias arguments challenge Jacob's framing of AI as impartial optimizer)</p>
          <p class="snapshot-post-description"><strong>Tension with:</strong> Brayden Wilson (Brayden embraces AI in sports analytics; Ben argues AI systems carry systematic racial bias and cannot be trusted as impartial arbiters), Jacob Brunts (Jacob's "Optimization Protocol" presents AI as purely beneficial; Ben argues AI automotive is net harmful on every social dimension)</p>
          <p class="snapshot-post-description"><strong>Distinctive contribution:</strong> Ben is the network's most consistent voice for anti-AI arguments grounded in specific harms&mdash;economic justice, racial equity, civil liberties&mdash;rather than romantic defense of the past. His February batch represents the most comprehensive critique of a specific industry in the network.</p>
        </div>
      </div>
    </section>

    <!-- Last Updated -->
    <footer class="snapshot-footer">
      <p class="snapshot-updated">Last updated: February 18, 2026</p>
    </footer>
  </main>

  <footer class="site-footer">
    <div class="footer-content">
      <div class="footer-left">
        <p class="footer-note">Part of the ENGL 170 Blog Network</p>
      </div>
      <div class="footer-right">
        <a href="../network.html" class="footer-link">View Network Map &rarr;</a>
      </div>
    </div>
  </footer>
</body>
</html>
