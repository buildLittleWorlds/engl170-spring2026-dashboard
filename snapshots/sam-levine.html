<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sam Levine | ENGL 170 Snapshot</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=Instrument+Sans:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <div class="grain-overlay"></div>

  <header class="site-header snapshot-header">
    <div class="header-content">
      <div class="masthead">
        <span class="issue-label">Writer Snapshot</span>
        <h1 class="site-title">Sam Levine</h1>
        <p class="site-subtitle">ENGL 170 · Composition II</p>
      </div>
      <div class="header-nav-group">
        <a href="https://samlevine277.github.io" target="_blank" rel="noopener" class="header-nav-link">Visit Blog &rarr;</a>
        <a href="../directory.html" class="header-nav-link">&larr; Directory</a>
      </div>
    </div>
  </header>

  <main class="main-content snapshot-content">
    <!-- Summary Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Overview</h2>
      <div class="snapshot-summary">
        <p>Sam explores AI across multiple domains -- sports, healthcare, the workforce, and human autonomy -- while carefully engaging with classmates' arguments. Her most developed thread examines AI in athletics, arguing that AI functions best as a performance partner that protects and augments human effort rather than replacing it. In her most recent work, Sam has expanded her framework to compare AI's different cultural effects: AI in the Olympics feels assistive because the stakes are human performance, while AI in the workforce threatens identity and livelihood -- the same technology, two different social contracts. Her emerging debate with Isabella Calmet on the "50/50 Rule" raises a harder question: if the "agency compression effect" (assist → optimize → disappear) is real, does the 50/50 split protect autonomy or just delay its erosion? Central insight: the question isn't whether AI enters the system, but whether humans retain genuine decision-making power at every stage.</p>
      </div>
    </section>

    <!-- Key Themes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Key Themes</h2>
      <ul class="theme-list">
        <li class="theme-item">AI as performance partner</li>
        <li class="theme-item">Scaffolding vs. shortcuts</li>
        <li class="theme-item">Hybrid automation systems</li>
        <li class="theme-item">Sports officiating fairness</li>
        <li class="theme-item">Injury prevention</li>
        <li class="theme-item">Cognitive dependence on AI</li>
        <li class="theme-item">Social media vs. AI addiction</li>
        <li class="theme-item">Curiosity cultivation</li>
        <li class="theme-item">Human autonomy</li>
        <li class="theme-item">AI in Olympics vs. workforce</li>
        <li class="theme-item">Agency compression effect</li>
        <li class="theme-item">Mastery atrophy and algorithmic drift</li>
      </ul>
    </section>

    <!-- Core Arguments Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Core Arguments</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Agency With Assistance</span>
          </div>
          <p class="snapshot-post-description">Responding to Zay Amaro's concern that automation erases moral agency in sports, Sam argues that hybrid systems preserve human accountability. MLB's Automated Ball-Strike system keeps umpires on the field while giving players the choice to challenge -- automation only intervenes when a human actively invokes it. The key distinction: moral agency disappears only when humans are removed from decision-making, not when technology enters the game. "Automation and human judgment don't have to be enemies."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Two Addictions, Both Real</span>
          </div>
          <p class="snapshot-post-description">Social media is the "loud" addiction -- emotional, visual, engineered through endless engagement. AI is the "quiet" addiction -- not compulsive scrolling, but cognitive reliance. When we automatically turn to AI for every question, we outsource thinking itself. Drawing on Jonathan Haidt's "The Anxious Generation," Sam argues the deeper issue isn't the existence of technology but the habits and dependencies we build around it. "Social media makes us scroll; AI makes us stop thinking for ourselves."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">Refining the Forklift Metaphor</span>
          </div>
          <p class="snapshot-post-description">Eliana Nodari explores Ted Chiang's "forklift in the weight room" metaphor with concern about bypassing effort. Sam refines it using Ethan Mollick: using a forklift to lift for someone entirely prevents growth, but using it to teach proper form, demonstrate technique, or safely engage with weights before strength develops can foster understanding. Intent is key -- AI is harmful when it replaces thinking you could do, helpful when it supports thinking you're still learning.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Soul Is in Human Effort, Not Injury</span>
          </div>
          <p class="snapshot-post-description">Pushes back strongly on the idea that injury is part of sport's "soul." Injuries aren't narrative magic -- they're trauma, loss, and permanent damage. Protecting athletes through AI doesn't erase humanity; it preserves it. The unpredictability worth protecting is the unpredictability of competition, not injury. "The soul of sport has never been in torn ligaments. It has always been in human effort."</p>
        </div>
      </div>
    </section>

    <!-- Notable Quotes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Notable Quotes</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description">"Social media makes us scroll; AI makes us stop thinking for ourselves."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"Moral agency doesn't disappear when technology enters the game. It disappears only when humans are removed from decision-making."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"The soul of sport has never been in torn ligaments. It has always been in human effort."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"The central question is not whether students use the forklift, but whether they are learning how to lift."</p>
        </div>
      </div>
    </section>

    <!-- Posts Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Posts</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/algorithmic-mirror-response.html" target="_blank" rel="noopener" class="snapshot-post-title">The 50/50 Rule Under Fire</a>
            <span class="snapshot-post-date">February 16, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Isabella Calmet's "Algorithmic Mirror." Sam takes on the 50/50 Rule's hardest challenge: if AI learns the "shape of our desires" and optimizes accordingly, can any rule sustain genuine human agency? Introduces the "agency compression effect" — the trajectory from AI as assistant, to optimizer, to invisible driver — and the "mastery atrophy feedback loop" as the mechanism by which users lose capability without noticing. Sam agrees the algorithmic mirror is becoming directive, but argues the solution is structural transparency and user education, not abandoning AI partnership. Coins "algorithmic mirror becoming directive" as the next phase of the autonomy debate.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-sports-vs-work.html" target="_blank" rel="noopener" class="snapshot-post-title">AI in Sports vs. Work</a>
            <span class="snapshot-post-date">February 15, 2026</span>
          </div>
          <p class="snapshot-post-description">Extends the Olympics/workforce comparison into a systematic analysis of why the same AI technology feels collaborative in one domain and threatening in another. In sports, AI enhances performance within a bounded competitive system — the human narrative (winning, losing, heroism, failure) stays intact. In the workplace, AI disrupts economic identity and threatens the social meaning of labor. The cultural framing, not the technology, determines whether AI is partner or predator. Argues for domain-specific ethical deployment strategies that account for what's at stake in each context.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/response-to-brayden-ai-olympics.html" target="_blank" rel="noopener" class="snapshot-post-title">AI in Olympics vs. Workforce</a>
            <span class="snapshot-post-date">February 11, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Brayden Wilson's AI-in-healthcare and sports training posts. Draws a sharp contrast: AI in the Olympics functions as an assistive performance tool within a system designed for human competition, while in the workforce AI poses genuine displacement risk — Brookings projects 30%+ of workers could see 50%+ of their tasks disrupted. Applies the Olympic motto "Communiter" (together) to argue that workforce AI deployment requires the same collaborative spirit that governs athletic AI: humans and machines sharing goals, not competing for them.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/automation_accountability_rugby_blog.html" target="_blank" rel="noopener" class="snapshot-post-title">Automation, Accountability, and the Myth of Lost Humanity</a>
            <span class="snapshot-post-date">February 9, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Jonas Rodrigues's "The Vibe Schism." Agrees that verification is the central task but diverges on the prescription: AI doesn't remove human agency, it shifts it upward from execution to judgment. Uses Karl Newell's constraints theory to argue that constraints enhance creativity rather than stifle it. Rugby parallel: AI recovery tools don't remove risk from tackles&mdash;they make risk deliberate and accountable. "Drama migrates rather than disappears." Automation concentrates responsibility where it matters.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/risk-automation-in-sports.html" target="_blank" rel="noopener" class="snapshot-post-title">Clarifying Risk: Why Automation Enhances Human Agency in Sport</a>
            <span class="snapshot-post-date">February 8, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Gabriel Bell's argument that error is the "soul of the game." Distinguishes between errors from player choice (meaningful) and errors from procedural arbitrariness (noise). Consistent automated officiating doesn't remove challenge&mdash;it relocates responsibility onto the players. Uses Karl Newell's constraints framework and personal rugby experience: knowing recovery limits makes risk deliberate, not careless. "Automation doesn't destroy the soul of sport. It protects the human story."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/off-script-not-offline.html" target="_blank" rel="noopener" class="snapshot-post-title">Off-Script, But Not Offline</a>
            <span class="snapshot-post-date">February 7, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Zay Amaro's "The Off-Script Athlete." Agrees that moral agency is essential to sport but pushes back on the idea that automation necessarily erases it. Uses MLB's upcoming Automated Ball-Strike (ABS) system as a case study for hybrid models: umpires still make calls, players choose when to challenge, coaches manage strategy. Automation supports fairness while humans retain narrative control and moral responsibility. "Automation and human judgment don't have to be enemies."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-vs-social-media.html" target="_blank" rel="noopener" class="snapshot-post-title">What's More Addicting: Social Media or AI?</a>
            <span class="snapshot-post-date">February 4, 2026</span>
          </div>
          <p class="snapshot-post-description">Challenges the assumption that social media is the only digital addiction worth discussing. Distinguishes social media's "loud" addiction (emotional, dopamine-driven, endless scroll) from AI's "quiet" addiction (cognitive reliance, outsourcing thinking). Draws on Jonathan Haidt's "The Anxious Generation" and screen-time research to argue that AI dependence reshapes cognition even without compulsive behavior. "Instead of only asking, 'Which is more addicting?' we should be asking: What kind of people are these tools training us to become?"</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-rugby.html" target="_blank" rel="noopener" class="snapshot-post-title">AI in Rugby: Performance Partner or Threat to Autonomy?</a>
            <span class="snapshot-post-date">February 2, 2026</span>
          </div>
          <p class="snapshot-post-description">Applies AI-as-partner framework to rugby tackling and injury prevention, engaging Trinity College Dublin's AI research on tackle technique analysis. AI can identify dangerous patterns in high-speed footage that coaches miss, potentially making the sport safer without removing human agency. Key insight: autonomy doesn't require acting without support -- rugby has always used teammates, coaches, trainers, and film review. "The future of rugby is not humans competing against machines. It is humans learning how to work alongside them."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-sports-response.html" target="_blank" rel="noopener" class="snapshot-post-title">AI-Sports Response: A Rebuttal to Dominic Debro</a>
            <span class="snapshot-post-date">February 1, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Dominic Debro's surveillance concerns. Directly challenges the claim that AI reduces effort or replaces human drive. From her perspective as an athlete, AI is a tool -- one of many. Athletic trainers combine AI data with knowledge of athlete's body, mindset, and fatigue. "AI provides information, but humans interpret it and make the final call." The human element -- discipline, judgment, resilience -- remains central to success.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-injury-prevention.html" target="_blank" rel="noopener" class="snapshot-post-title">AI Injury Prevention Preserves the Soul of Sports</a>
            <span class="snapshot-post-date">January 29, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Zay Amaro's "Hacking the Limit." Pushes back strongly on the idea that injury is part of sport's "soul." Injuries aren't narrative magic -- they're trauma, loss, and permanent damage. Protecting athletes through AI doesn't erase humanity; it preserves it. The unpredictability worth protecting is the unpredictability of competition, not injury.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-performance-partner.html" target="_blank" rel="noopener" class="snapshot-post-title">AI as a Performance Partner, Not a Replacement</a>
            <span class="snapshot-post-date">January 26, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Jeffrey Way's video. Draws on Ethan Mollick's "Co-Intelligence" to argue AI works best as a partner, not replacement. "The real promise of AI isn't automation -- it's augmentation." Compares AI to training tools in athletics: coaches and technology support performance without replacing the athlete.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-vs-humans.html" target="_blank" rel="noopener" class="snapshot-post-title">AI vs Humans (Sports): The Human Element vs. AI in Sports</a>
            <span class="snapshot-post-date">January 25, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Zay Amaro's sports posts. Nuances the "human vs. AI" debate: agrees that emotion and intentionality resist quantification, but argues analytics isn't the enemy. The "25% chance" where probability fails is where human improvisation lives. Proposes partnership rather than replacement.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-autonomy.html" target="_blank" rel="noopener" class="snapshot-post-title">AI Autonomy</a>
            <span class="snapshot-post-date">January 21, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Jonas Rodrigues's "AI Balancing Act." Explores the tension between AI as tool vs. crutch. Draws on Sherry Turkle ("We expect more from technology and less from each other") to argue the real risk is reduced tolerance for struggle. The word at stake: autonomy -- not just making choices, but developing ideas independently.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-safety.html" target="_blank" rel="noopener" class="snapshot-post-title">AI Safety</a>
            <span class="snapshot-post-date">January 19, 2026</span>
          </div>
          <p class="snapshot-post-description">Explores AI safety concerns and considerations for responsible development and deployment.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-officiating.html" target="_blank" rel="noopener" class="snapshot-post-title">AI Officiatings</a>
            <span class="snapshot-post-date">January 19, 2026</span>
          </div>
          <p class="snapshot-post-description">Examines the role of AI in sports officiating and refereeing decisions, connecting to Kevion's work on the topic.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/forklifts-and-fundamentals.html" target="_blank" rel="noopener" class="snapshot-post-title">Forklifts and Fundamentals: AI, Guidance, and Learning</a>
            <span class="snapshot-post-date">January 18, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Eliana Nodari's exploration of Ted Chiang's forklift metaphor. Uses Ethan Mollick's "Co-Intelligence" to distinguish between AI that replaces thinking and AI that supports developing learners. Argues many students turn to AI not for laziness but uncertainty -- AI can be a tutor. Proposes that struggle and support aren't mutually exclusive.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-ocean.html" target="_blank" rel="noopener" class="snapshot-post-title">My Thoughts on AI Affecting The Ocean</a>
            <span class="snapshot-post-date">January 18, 2026</span>
          </div>
          <p class="snapshot-post-description">Explores AI applications in ocean research and environmental monitoring.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://samlevine277.github.io/ai-writing-tools.html" target="_blank" rel="noopener" class="snapshot-post-title">My Thoughts on AI Writing Tools</a>
            <span class="snapshot-post-date">January 18, 2026</span>
          </div>
          <p class="snapshot-post-description">Reflects on AI writing assistants and their role in the composition process.</p>
        </div>
      </div>
    </section>

    <!-- Key Sources Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Key Sources Engaged</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description"><strong>Ethan Mollick</strong> - "Co-Intelligence: Living and Working with AI"</p>
          <p class="snapshot-post-description"><strong>Jonathan Haidt</strong> - "The Anxious Generation"</p>
          <p class="snapshot-post-description"><strong>Sherry Turkle</strong> - MIT professor on technology and human behavior</p>
          <p class="snapshot-post-description"><strong>Ted Chiang</strong> - Forklift metaphor (via Eliana)</p>
          <p class="snapshot-post-description"><strong>Trinity College Dublin</strong> - AI rugby tackle analysis research</p>
          <p class="snapshot-post-description"><strong>Associated Press</strong> - MLB Automated Ball-Strike system reporting</p>
        </div>
      </div>
    </section>

    <!-- Connections Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Network Connections</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description"><strong>Responds to:</strong> Eliana Nodari's "Using AI to Elevate Thinking"; Jonas Rodrigues's "The AI Balancing Act"; Zay Amaro's "Hacking the Limit," "The Off-Script Athlete," and sports posts; Dominic Debro's surveillance concerns; Jeffrey Way's "I'm Done" video</p>
          <p class="snapshot-post-description"><strong>Responded to by:</strong> Eliana Nodari in "The Digital Dual-Threat" (extends Sam's social media vs. AI addiction framework); Jacob Brunts in "The Quantified Athlete" and "The Lazarus Protocol"</p>
          <p class="snapshot-post-description"><strong>In dialogue with:</strong> Zay Amaro -- Sam and Zay represent a key network debate on automation in sports. Zay defends human moral agency and the value of going "off-script"; Sam argues hybrid systems like ABS preserve agency while improving fairness. Both agree on human relevancy but disagree on where automation crosses the line.</p>
          <p class="snapshot-post-description"><strong>Thematic overlap:</strong> Emani Gerdine (cognitive partnership), Kevion Milton (sports officiating), Jonas Rodrigues (balance/moderation emphasis), Ben Teismann (autonomy concerns), Brayden Wilson ("Glass Athlete" debate)</p>
        </div>
      </div>
    </section>

    <!-- Last Updated -->
    <footer class="snapshot-footer">
      <p class="snapshot-updated">Last updated: February 18, 2026</p>
    </footer>
  </main>

  <footer class="site-footer">
    <div class="footer-content">
      <div class="footer-left">
        <p class="footer-note">Part of the ENGL 170 Blog Network</p>
      </div>
      <div class="footer-right">
        <a href="../network.html" class="footer-link">View Network Map &rarr;</a>
      </div>
    </div>
  </footer>
</body>
</html>
