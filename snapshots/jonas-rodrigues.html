<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Jonas Rodrigues | ENGL 170 Snapshot</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;1,400&family=Instrument+Sans:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <div class="grain-overlay"></div>

  <header class="site-header snapshot-header">
    <div class="header-content">
      <div class="masthead">
        <span class="issue-label">Writer Snapshot</span>
        <h1 class="site-title">Jonas Rodrigues</h1>
        <p class="site-subtitle">ENGL 170 · Composition II</p>
      </div>
      <div class="header-nav-group">
        <a href="https://qubitn.github.io" target="_blank" rel="noopener" class="header-nav-link">Visit Blog &rarr;</a>
        <a href="../directory.html" class="header-nav-link">&larr; Directory</a>
      </div>
    </div>
  </header>

  <main class="main-content snapshot-content">
    <!-- Summary Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Overview</h2>
      <div class="snapshot-summary">
        <p>Jonas explores AI through extended metaphors and cross-domain applications, from ancient history to everyday navigation to civil engineering to the music industry. His "GPS and the Driver" metaphor has become a touchstone in the network, and his "Calibrated Trust" framework offers a practical response to the vibe coding era. Central insight: the "Cognitive Partner" is only valuable if the human partner has enough expertise to recognize when the GPS is wrong. His most recent pair of posts marks a significant shift: from AI critic to AI analyst. "The Great Phase Change" provides an exhaustive survey of the February 2026 AI landscape&mdash;agentic orchestration, the "SaaSpocalypse," the T-shaped developer, and the concept of "Taste" as the last irreplaceable human skill. "Prompt to Root" demonstrates these ideas in action, covering Claude Code's terminal integration in Arch Linux and arguing that NL2SH translation represents a genuine paradigm shift in system administration. These posts have generated significant network engagement, with Zay Amaro, Caleb Murphy, and Sam Levine all responding to the "Taste" concept.</p>
      </div>
    </section>

    <!-- Key Themes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Key Themes</h2>
      <ul class="theme-list">
        <li class="theme-item">AI as GPS metaphor</li>
        <li class="theme-item">Calibrated trust</li>
        <li class="theme-item">Gamification of creativity</li>
        <li class="theme-item">Cognitive atrophy</li>
        <li class="theme-item">Science vs. technology divergence</li>
        <li class="theme-item">Vibe coding critique</li>
        <li class="theme-item">Material disengagement</li>
        <li class="theme-item">AI in civil engineering</li>
        <li class="theme-item">Global South perspectives</li>
        <li class="theme-item">Deskilling and narcissistic feedback loops</li>
      </ul>
    </section>

    <!-- Core Arguments Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Core Arguments</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Gamification Trap</span>
          </div>
          <p class="snapshot-post-description">Responding to Adam Neely's critique of AI music platforms like Suno, Jonas argues that the "gamification" of music is a sociopolitical maneuver designed to bypass labor and extract wealth by debasing an ancient art form. Suno's CEO explicitly aims to make music as big as gaming by turning songwriting into a "text-prompt slot machine." The forces driving this -- deskilling, hyper-individualism, and "antisocial listening" -- are too corrosive to be contained. Even live performance won't be a safe harbor: audiences conditioned for instant gratification will lose patience for the imperfections of human performance. "The game is rigged, and if we keep playing by Silicon Valley's rules, human creativity is going to lose."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The GPS Risk</span>
          </div>
          <p class="snapshot-post-description">Emani's GPS metaphor is "perfect" -- the GPS doesn't drive, it optimizes the route. But Jonas adds a caveat: "We've all heard stories of people who blindly followed their GPS into a lake." If we rely on AI to organize every thought, do we lose our internal sense of direction? The Cognitive Partner is only valuable if the human can recognize when the GPS is wrong.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Mastermind vs. Vibe Coding</span>
          </div>
          <p class="snapshot-post-description">Response to Jeffrey Way's "I'm Done." The "vibe coding" era is a productivity trap: features that previously took weeks can now be "technically" finished in 20 minutes, but without a human to audit, the codebase accumulates "junk." Proposes the "Calibrated Trust" framework: Architect First (define interfaces before prompting), Demote AI to Junior Developer (rigorous review), and Maintain Mastery (periodically write by hand). "We are the site foremen ensuring the skyscraper doesn't lean."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <span class="snapshot-post-title">The Great Divergence</span>
          </div>
          <p class="snapshot-post-description">Science and technology were once symbiotic -- you studied electricity to understand the universe; you built a lightbulb to banish the dark. But AI as Science (curious, rigorous, slow) has diverged from AI as Technology (scalable, profit-driven, fast). We've built systems capable of incredible feats but lack fundamental understanding of how they achieve results. "The engineers are building faster than the architects can draw the blueprints."</p>
        </div>
      </div>
    </section>

    <!-- Notable Quotes Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Notable Quotes</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description">"The game is rigged, and if we keep playing by Silicon Valley's rules, human creativity is going to lose."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"We've all heard stories of people who blindly followed their GPS into a lake or down a closed road because they stopped looking at the actual terrain."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"We are no longer laborers laying individual bricks; we are the site foremen ensuring the skyscraper doesn't lean."</p>
        </div>
        <div class="snapshot-post">
          <p class="snapshot-post-description">"The engineers are building faster than the architects can draw the blueprints."</p>
        </div>
      </div>
    </section>

    <!-- Posts Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Posts</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/the-great-phase-change.html" target="_blank" rel="noopener" class="snapshot-post-title">The Great Phase Change</a>
            <span class="snapshot-post-date">February 12, 2026</span>
          </div>
          <p class="snapshot-post-description">Maps the February 2026 AI landscape as an "Agentic Orchestration" phase change—distinct from the Vibe Coding era that preceded it. Contrasts front-end "Vibe Coding" (disposable, prompt-driven) with back-end Orchestration (multi-agent pipelines building real infrastructure). Cites the Claude Opus 4.6 milestone and a 16-agent Rust compiler as evidence the shift is real. Predicts a "SaaSpocalypse" as agents replace entire SaaS categories. Proposes the T-shaped developer as the future survivor—broad breadth, one deep mastery. Coins "Taste" as the irreplaceable human skill: the ability to know when AI output is good enough. Introduces the "Agent-to-Human Ratio" as the key performance metric for the next decade.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/prompt-to-root.html" target="_blank" rel="noopener" class="snapshot-post-title">Prompt to Root</a>
            <span class="snapshot-post-date">February 12, 2026</span>
          </div>
          <p class="snapshot-post-description">Follows a hands-on experiment with Claude Code in an Arch Linux terminal, prompted by the Basically Homeless YouTube channel. Frames AI-assisted shell work as an "NL2SH translation paradigm shift"—natural language replacing syntax memorization. Distinguishes agentic AI (self-evaluating, autonomous) from assistive AI (reactive). Grapples with the efficiency paradox: the tool that helps you skip learning may also prevent you from ever learning. Asks whether AI should be framed as servant (do this for me) or mentor (teach me as we go), and argues the framing determines whether the user gains or loses capability.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/vibe-schism.html" target="_blank" rel="noopener" class="snapshot-post-title">The Vibe Schism: Factory Farming Code vs. The Art of Verification</a>
            <span class="snapshot-post-date">February 8, 2026</span>
          </div>
          <p class="snapshot-post-description">Compares Steve Yegge's "Industrialist" vision of agentic engineering (code as disposable byproduct, AI as "interns in a box") against Jonas's own "Conservationist" position. Yegge, Karpathy, and Jonas all agree AI agents are reckless junior developers&mdash;but disagree on the response. The Industrialist builds orchestration frameworks; the Conservationist maintains mastery. Data supports conservatism: AI-assisted Pull Requests have 1.7x more issues, technical debt grows 30-41%, and AI introduces security vulnerabilities in 45% of cases. Predicts the future battle will be Creation vs. Verification: "writing code is free, but verifying code is expensive." The most valuable engineers will be "10x Verifiers," not "10x creators."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/gamification-music.html" target="_blank" rel="noopener" class="snapshot-post-title">Cognitive Atrophy: How the "Gamification" of Music Rewires the Audience</a>
            <span class="snapshot-post-date">February 4, 2026</span>
          </div>
          <p class="snapshot-post-description">Responds to Adam Neely's critique of generative AI music platforms (Suno, Udio). Argues that gamification replaces deep engagement with dopamine-driven feedback loops, turning songwriting into a "text-prompt slot machine." Identifies four threats: deskilling through "impatience as virtue," narcissistic feedback loops of "antisocial listening," economic displacement of human musicians by AI DJs, and a "copyright vacuum" that incentivizes corporations to flood the market with royalty-free AI tracks. Challenges Neely's hope that live performance will be a refuge -- audiences conditioned for instant gratification will lose patience for human imperfection.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/post-ai-development.html" target="_blank" rel="noopener" class="snapshot-post-title">Post-AI Development: Surviving the Era of Material Disengagement</a>
            <span class="snapshot-post-date">February 2, 2026</span>
          </div>
          <p class="snapshot-post-description">Examines "vibe coding" as it graduates to enterprise environments. Cites research on the "productivity paradox" -- developers estimated 20% faster but were actually 19% slower due to debugging AI errors. AI leads to "material disengagement" and 17% decrease in mastery. Warns of "insecure spaghetti" -- heterogeneous code with outdated encryption. Solution: "Calibrated Trust" framework with three principles: Architect First, Demote AI to Junior Developer, and Maintain Mastery.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/mastermind-machine.html" target="_blank" rel="noopener" class="snapshot-post-title">The Mastermind in the Machine: Why "Vibe Coding" Still Needs a Captain</a>
            <span class="snapshot-post-date">January 29, 2026</span>
          </div>
          <p class="snapshot-post-description">Response to Jeffrey Way's "I'm Done." While Way admits AI has devastated and energized his work simultaneously, Jonas warns against the "vibe coding" narrative -- the idea we can "vibe" our way to a finished product. Features finished in 20 minutes still require hours of human review to prevent "junk" accumulation. "Productivity requires the machine, but a great program still requires a human mastermind to sign off on the vibe."</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/great-divergence.html" target="_blank" rel="noopener" class="snapshot-post-title">The Great Divergence: Why AI Needs Science to Catch Up to Technology</a>
            <span class="snapshot-post-date">January 29, 2026</span>
          </div>
          <p class="snapshot-post-description">Examines the dangerous split between AI as Science (cognitive psychologists, ethicists, mathematicians seeking understanding) and AI as Technology (Silicon Valley giants seeking scalability and market capture). Technology vastly outpaces science -- we've built systems without fundamental understanding of how they work. The "move fast and break things" ethos is ill-suited for autonomous systems. Calls for a "culturally enforced pause" to let science catch its breath.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/ai-civil-engineering.html" target="_blank" rel="noopener" class="snapshot-post-title">The Invisible Architect: How AI is Rebuilding Civil Engineering</a>
            <span class="snapshot-post-date">January 29, 2026</span>
          </div>
          <p class="snapshot-post-description">Explores AI applications in civil engineering: Generative Design (algorithms testing thousands of structural possibilities), Digital Twins (virtual replicas with real-time sensor data), and AI-driven traffic management for smart cities. Raises the ethical question: if AI designs a structure, who is liable if it fails? The "black box" nature means engineers must understand why an AI recommends a design -- AI serves safety but cannot replace accountability.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/beyond-silicon-valley.html" target="_blank" rel="noopener" class="snapshot-post-title">Beyond Silicon Valley: What the Global South Can Teach Us About AI in the Classroom</a>
            <span class="snapshot-post-date">January 23, 2026</span>
          </div>
          <p class="snapshot-post-description">Challenges the Western "efficiency and integrity" framing of AI in education. Through Ubuntu (African), Confucian (East Asian), and Indigenous lenses, argues education is about <em>formation</em> not transaction. Ubuntu asks how AI can help a class solve community problems together. Confucianism questions whether a machine without moral character can be a "teacher." Indigenous data sovereignty challenges AI's "scraping" as digital colonialism.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/double-edged-sword.html" target="_blank" rel="noopener" class="snapshot-post-title">The Double-Edged Sword: How AI is Rewriting the Script in Hollywood</a>
            <span class="snapshot-post-date">January 23, 2026</span>
          </div>
          <p class="snapshot-post-description">Examines AI's transformation of filmmaking -- from predictive script analysis to de-aging VFX to scriptwriting assistance. Explores four ethical quandaries: job displacement, the battle over likeness and consent (digital replicas), the threat of creative homogenization if algorithms greenlight based on past success, and inherited bias from training data.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/resurrecting-ancient-rome.html" target="_blank" rel="noopener" class="snapshot-post-title">How Artificial Intelligence is Resurrecting Ancient Rome</a>
            <span class="snapshot-post-date">January 18, 2026</span>
          </div>
          <p class="snapshot-post-description">Explores positive use cases for AI in historical research and reconstruction of ancient civilizations. Demonstrates how AI can serve scholarship in domains beyond the typical education/writing debates.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/gps-and-driver.html" target="_blank" rel="noopener" class="snapshot-post-title">The GPS and the Driver: A Response to Emani Gerdine</a>
            <span class="snapshot-post-date">January 16, 2026</span>
          </div>
          <p class="snapshot-post-description">Responds to Emani's "AI as a Cognitive Partner" by extending the GPS metaphor with warnings. Agrees that AI as navigation system is apt, but emphasizes the risk of blind following. Refines "Ethical Opacity" concept: opacity requires you actually did the climbing. Proposes synthesis: embrace the GPS but maintain internal compass.</p>
        </div>

        <div class="snapshot-post">
          <div class="snapshot-post-header">
            <a href="https://qubitn.github.io/ai-balancing-act.html" target="_blank" rel="noopener" class="snapshot-post-title">The AI Balancing Act</a>
            <span class="snapshot-post-date">January 16, 2026</span>
          </div>
          <p class="snapshot-post-description">Initial argument that AI should be treated as tool rather than crutch. Warns against "beige" content from outsourcing thinking. Introduces concern about skill atrophy -- the worry that skills unused will decay.</p>
        </div>
      </div>
    </section>

    <!-- Connections Section -->
    <section class="snapshot-section">
      <h2 class="section-heading">Network Connections</h2>
      <div class="snapshot-posts">
        <div class="snapshot-post">
          <p class="snapshot-post-description"><strong>Responds to:</strong> Emani Gerdine's "AI as a Cognitive Partner"; Jeffrey Way's "I'm Done" video; Adam Neely's AI music critique</p>
          <p class="snapshot-post-description"><strong>Responded to by:</strong> Dominic Debro in "From Architect to Visionary" (challenges the "site foreman" as transitional role); Eliana Nodari in "The Slot-Machine Symphony" (extends music gamification argument through Walter Benjamin's "aura" concept); Sam Levine in "AI Autonomy" (explores the GPS risk further)</p>
          <p class="snapshot-post-description"><strong>In dialogue with:</strong> Eliana Nodari -- Jonas and Eliana are developing a sustained exchange on creativity and AI. His "Cognitive Atrophy" post prompted her "Slot-Machine Symphony" response. Both see deskilling as a central danger, but Jonas is more pessimistic about live performance surviving, while Eliana finds more room for AI as "digital apprentice."</p>
          <p class="snapshot-post-description"><strong>Thematic overlap:</strong> Gabriel Bell (concern about skill atrophy), Jacob Brunts (vibe coding critique), Caleb Murphy (developer-driven AI), Dr. Plate (planning as thinking), Emani Gerdine (productive back-and-forth on GPS metaphor)</p>
        </div>
      </div>
    </section>

    <!-- Last Updated -->
    <footer class="snapshot-footer">
      <p class="snapshot-updated">Last updated: February 18, 2026</p>
    </footer>
  </main>

  <footer class="site-footer">
    <div class="footer-content">
      <div class="footer-left">
        <p class="footer-note">Part of the ENGL 170 Blog Network</p>
      </div>
      <div class="footer-right">
        <a href="../network.html" class="footer-link">View Network Map &rarr;</a>
      </div>
    </div>
  </footer>
</body>
</html>
